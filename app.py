# app.py
import asyncio
import re
from datetime import datetime
from zoneinfo import ZoneInfo

import pandas as pd
from playwright.async_api import async_playwright, TimeoutError as PWTimeout

KST = ZoneInfo("Asia/Seoul")

BEST_URL = "https://www.oliveyoung.co.kr/store/main/getBestList.do"

# ì‚¬ì´íŠ¸ ê°œí¸/ABí…ŒìŠ¤íŠ¸ ëŒ€ì‘: í›„ë³´ ì…€ë ‰í„°ë¥¼ ë„“ê²Œ ì¡ê³ , ì²« ë§¤ì¹­ì„ ì‚¬ìš©
# (ì‰¼í‘œë¡œ ë¬¶ìœ¼ë©´ "OR"ì²˜ëŸ¼ ë™ì‘)
PRODUCT_LIST_SELECTORS = [
    "ul.tab_cont_list li",           # ê³¼ê±° ì…€ë ‰í„°
    "ul.cate_prd_list li",           # ë˜ ë‹¤ë¥¸ ê³¼ê±° ì…€ë ‰í„°
    "ul.prd_list li",                # ì¼ë°˜ ë¦¬ìŠ¤íŠ¸
    "div.best_prd_area ul li",       # ë² ìŠ¤íŠ¸ ì˜ì—­ ë¦¬ìŠ¤íŠ¸
    "div#Container ul li",           # ìµœí›„ì˜ ë³´ë£¨
    ".ranking_list .prd_info",       # ë­í‚¹ ë¦¬ìŠ¤íŠ¸
    ".cate_prd_list > li",           # ì¹´í…Œê³ ë¦¬ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸
    "ul li",                         # ì¼ë°˜ì ì¸ ë¦¬ìŠ¤íŠ¸
]

# ê° ì¹´ë“œ ë‚´ë¶€ì—ì„œ ì‹œë„í•  í•˜ìœ„ ì…€ë ‰í„°(ì—¬ëŸ¬ í›„ë³´)
NAME_CANDIDATES = [
    ".tx_name", ".prd_name", ".name", "a .name", "strong", "a[title]", ".prd_info .name"
]
PRICE_CANDIDATES = [
    ".tx_cur", ".cur_price", ".price .num", ".price", ".won", ".cost", ".prd_info .price"
]
RANK_CANDIDATES = [
    ".tx_num", ".num", ".rank", ".best_num", "em", "i", ".prd_info .rank"
]
LINK_CANDIDATES = [
    "a", "a.prd_thumb", "a.prd_info", ".prd_info a"
]

# ì ˆëŒ€ URLë¡œ ë³€í™˜
def to_abs(url: str) -> str:
    if not url:
        return ""
    if url.startswith("http"):
        return url
    return "https://www.oliveyoung.co.kr" + (url if url.startswith("/") else f"/{url}")

async def extract_first_text(card, selectors):
    for sel in selectors:
        try:
            el = await card.query_selector(sel)
            if el:
                txt = (await el.get_attribute("title") or "").strip() or (await el.inner_text() or "").strip()
                if txt:
                    return txt
        except:
            continue
    return ""

async def extract_first_href(card, selectors):
    for sel in selectors:
        try:
            el = await card.query_selector(sel)
            if el:
                href = await el.get_attribute("href") or ""
                if href:
                    return to_abs(href)
        except:
            continue
    return ""

def clean_price(text: str) -> float | None:
    if not text:
        return None
    # ìˆ«ìë§Œ ì¡ì•„ë‚´ê¸°
    m = re.findall(r"\d+", text.replace(",", ""))
    if not m:
        return None
    try:
        return float("".join(m))
    except:
        return None

def clean_rank(text: str) -> float | None:
    if not text:
        return None
    m = re.search(r"\d+", text)
    if not m:
        return None
    try:
        return float(m.group())
    except:
        return None

async def wait_for_any_selector(page, selectors, timeout_ms=30000):
    """
    ì—¬ëŸ¬ í›„ë³´ ì…€ë ‰í„° ì¤‘ í•˜ë‚˜ë¼ë„ ë“±ì¥í•  ë•Œê¹Œì§€ ëŒ€ê¸°.
    """
    # ê° ì…€ë ‰í„°ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì‹œë„
    for selector in selectors:
        try:
            await page.locator(selector).first.wait_for(state="visible", timeout=timeout_ms)
            print(f"âœ… ì…€ë ‰í„° '{selector}' ë°œê²¬")
            return True
        except PWTimeout:
            print(f"âš ï¸ ì…€ë ‰í„° '{selector}' ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼")
            continue
    
    print("âŒ ëª¨ë“  ì…€ë ‰í„°ì—ì„œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return False

async def smart_scroll(page, step_px=1200, max_rounds=15, pause_ms=300):
    """
    ë¬´í•œ ìŠ¤í¬ë¡¤/ì§€ì—° ë¡œë”© ëŒ€ë¹„: ì•„ë˜ë¡œ ì—¬ëŸ¬ ë²ˆ ìŠ¤í¬ë¡¤
    """
    last_height = await page.evaluate("() => document.body.scrollHeight")
    rounds = 0
    while rounds < max_rounds:
        rounds += 1
        await page.evaluate(f"window.scrollBy(0, {step_px})")
        await page.wait_for_timeout(pause_ms)
        
        new_height = await page.evaluate("() => document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

async def scrape_oliveyoung():
    """
    ì˜¬ë¦¬ë¸Œì˜ ë² ìŠ¤íŠ¸ ìƒí’ˆ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘ (Playwright ìš°íšŒ)")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-accelerated-2d-canvas",
                "--no-first-run",
                "--no-zygote",
                "--disable-gpu"
            ]
        )
        
        page = await browser.new_page()
        
        # User-Agent ì„¤ì •
        await page.set_extra_http_headers({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        })
        
        # JavaScript ì‹¤í–‰ ë°©ì§€ ìš°íšŒ
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
        """)
        
        try:
            print(f"ğŸŒ í˜ì´ì§€ ë¡œë”© ì¤‘: {BEST_URL}")
            await page.goto(BEST_URL, wait_until="domcontentloaded", timeout=60000)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            await page.wait_for_timeout(5000)
            
            # í˜ì´ì§€ ì†ŒìŠ¤ í™•ì¸
            content = await page.content()
            print(f"ğŸ“„ í˜ì´ì§€ ë‚´ìš© ê¸¸ì´: {len(content)}")
            
            # í˜ì´ì§€ ì œëª© í™•ì¸
            title = await page.title()
            print(f"ğŸ“‹ í˜ì´ì§€ ì œëª©: {title}")
            
            # í˜„ì¬ URL í™•ì¸
            current_url = page.url
            print(f"ğŸ”— í˜„ì¬ URL: {current_url}")
            
            # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì…€ë ‰í„° ëŒ€ê¸°
            print("ğŸ” ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ìš”ì†Œ ëŒ€ê¸° ì¤‘...")
            if not await wait_for_any_selector(page, PRODUCT_LIST_SELECTORS, timeout_ms=35000):
                print("âš ï¸ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²• ì‹œë„...")
                
                # í˜ì´ì§€ ë‚´ìš©ì—ì„œ ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
                content_lower = content.lower()
                keywords = ["ìƒí’ˆ", "ë­í‚¹", "ë² ìŠ¤íŠ¸", "ì œí’ˆ", "ìƒí’ˆëª…", "ê°€ê²©"]
                found_keywords = [kw for kw in keywords if kw in content_lower]
                
                if found_keywords:
                    print(f"âœ… í˜ì´ì§€ì— ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œ ë°œê²¬: {found_keywords}")
                    
                    # ë‹¤ë¥¸ ì ‘ê·¼ ë°©ë²• ì‹œë„ - ë” ì¼ë°˜ì ì¸ ì…€ë ‰í„°
                    alternative_selectors = [
                        "li", "div", "a[href*='product']", "a[href*='goods']",
                        ".item", ".product", ".goods", "[class*='prd']", "[class*='item']"
                    ]
                    
                    print("ğŸ”„ ëŒ€ì•ˆ ì…€ë ‰í„°ë¡œ ì‹œë„ ì¤‘...")
                    for selector in alternative_selectors:
                        try:
                            elements = await page.query_selector_all(selector)
                            if len(elements) > 0:
                                print(f"âœ… ì…€ë ‰í„° '{selector}'ë¡œ {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬")
                                # ì´ ìš”ì†Œë“¤ì„ ìƒí’ˆìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì²˜ë¦¬
                                break
                        except:
                            continue
                    else:
                        print("âŒ ëŒ€ì•ˆ ì…€ë ‰í„°ë¡œë„ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return pd.DataFrame()
                else:
                    print("âŒ í˜ì´ì§€ì— ìƒí’ˆ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
            
            # ìŠ¤í¬ë¡¤ë¡œ ë” ë§ì€ ìƒí’ˆ ë¡œë“œ
            print("ğŸ“œ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
            await smart_scroll(page, step_px=800, max_rounds=10, pause_ms=500)
            
            # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
            print("ğŸ“Š ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘...")
            products = []
            
            # ì—¬ëŸ¬ ì…€ë ‰í„°ë¡œ ìƒí’ˆ ì°¾ê¸°
            items = []
            for selector in PRODUCT_LIST_SELECTORS:
                try:
                    items = await page.query_selector_all(selector)
                    if items:
                        print(f"âœ… ì…€ë ‰í„° '{selector}'ë¡œ {len(items)}ê°œ ìƒí’ˆ ë°œê²¬")
                        break
                except:
                    continue
            else:
                # ëŒ€ì•ˆ ì…€ë ‰í„° ì‚¬ìš©
                for selector in alternative_selectors:
                    try:
                        items = await page.query_selector_all(selector)
                        if len(items) > 0:
                            print(f"âœ… ëŒ€ì•ˆ ì…€ë ‰í„° '{selector}'ë¡œ {len(items)}ê°œ ìš”ì†Œ ë°œê²¬")
                            break
                    except:
                        continue
                else:
                    print("âŒ ì–´ë–¤ ì…€ë ‰í„°ë¡œë„ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()
            
            for i, item in enumerate(items[:100]):  # ìµœëŒ€ 100ê°œ
                try:
                    # ìƒí’ˆëª… ì¶”ì¶œ
                    name = await extract_first_text(item, NAME_CANDIDATES)
                    if not name:
                        continue
                    
                    # ê°€ê²© ì¶”ì¶œ
                    price_text = await extract_first_text(item, PRICE_CANDIDATES)
                    price = clean_price(price_text)
                    
                    # ë§í¬ ì¶”ì¶œ
                    link = await extract_first_href(item, LINK_CANDIDATES)
                    
                    # ìˆœìœ„ ì¶”ì¶œ (ì¸ë±ìŠ¤ ê¸°ë°˜)
                    rank = i + 1
                    
                    products.append({
                        "rank": rank,
                        "title": name,
                        "price": price_text if price_text else "ê°€ê²© ì •ë³´ ì—†ìŒ",
                        "price_num": price,
                        "link": link,
                        "timestamp": datetime.now(KST).isoformat()
                    })
                    
                except Exception as e:
                    print(f"âš ï¸ ìƒí’ˆ {i+1} íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            print(f"âœ… ì´ {len(products)}ê°œ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            
            if not products:
                print("âŒ ìˆ˜ì§‘ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(products)
            df = df.sort_values("rank").reset_index(drop=True)
            
            # ê²°ê³¼ ì €ì¥
            today = datetime.now(KST).strftime("%Y-%m-%d")
            filename = f"ranking_{today}.json"
            df.to_json(filename, orient="records", force_ascii=False, indent=2)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {filename}")
            
            return df
            
        except Exception as e:
            print(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()
        finally:
            await browser.close()

if __name__ == "__main__":
    try:
        df_today = asyncio.run(scrape_oliveyoung())
        if not df_today.empty:
            print("\nğŸ“Š ìˆ˜ì§‘ëœ ìƒí’ˆ ì •ë³´:")
            print(df_today[["rank", "title", "price"]].head(10))
        else:
            print("âŒ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
