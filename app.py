import os
import asyncio
import pandas as pd
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright
import requests
import re

# í™˜ê²½ë³€ìˆ˜
DROPBOX_TOKEN = os.environ.get("DROPBOX_ACCESS_TOKEN")
SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")

BASE_URL = "https://www.oliveyoung.co.kr/store/main/getBestList.do"

# Dropbox ì—…ë¡œë“œ
def upload_to_dropbox(local_path, dropbox_path):
    with open(local_path, "rb") as f:
        data = f.read()
    headers = {
        "Authorization": f"Bearer {DROPBOX_TOKEN}",
        "Dropbox-API-Arg": f'{{"path": "{dropbox_path}", "mode": "overwrite"}}',
        "Content-Type": "application/octet-stream"
    }
    r = requests.post("https://content.dropboxapi.com/2/files/upload", headers=headers, data=data)
    print("âœ… Dropbox ì—…ë¡œë“œ ì„±ê³µ" if r.status_code == 200 else f"âŒ Dropbox ì—…ë¡œë“œ ì‹¤íŒ¨: {r.text}")

# Slack ë©”ì‹œì§€ ì „ì†¡
def send_slack_message(text):
    payload = {"text": text}
    r = requests.post(SLACK_WEBHOOK_URL, json=payload)
    print("âœ… Slack ì „ì†¡ ì„±ê³µ" if r.status_code == 200 else f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {r.text}")

# ì˜¬ë¦¬ë¸Œì˜ í¬ë¡¤ë§ (Playwright ìš°íšŒ)
async def scrape_oliveyoung():
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘ (Playwright ìš°íšŒ)")
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(BASE_URL, timeout=60000)
        html = await page.content()
        await browser.close()

    soup = BeautifulSoup(html, "html.parser")
    items = soup.select("ul.cate_prd_list li")
    data = []
    for item in items:
        rank_tag = item.select_one("span.num")
        name_tag = item.select_one("p.tx_name")
        price_tag = item.select_one("span.tx_num")
        link_tag = item.select_one("a")

        if not name_tag or not price_tag or not link_tag:
            continue

        raw_rank = rank_tag.get_text(strip=True) if rank_tag else ""
        is_special = "ì˜¤íŠ¹" in raw_rank or not raw_rank.strip()
        display_rank = "" if is_special else raw_rank

        name = name_tag.get_text(strip=True)
        price = price_tag.get_text(strip=True)
        href = link_tag.get("href", "")
        if not href.startswith("http"):
            href = f"https://www.oliveyoung.co.kr{href}"
        clean_url = re.sub(r"\s+", "", href.split("?")[0])

        data.append({
            "ìˆœìœ„": display_rank,
            "ì˜¤íŠ¹": "ì˜¤íŠ¹" if is_special else "",
            "ì œí’ˆëª…": name,
            "URL": clean_url,
            "ê°€ê²©": price
        })

    df = pd.DataFrame(data)
    df["ìˆœìœ„"] = df["ìˆœìœ„"].replace("", pd.NA).fillna(method="ffill").astype(int)
    return df

# ê¸‰ìƒìŠ¹Â·ê¸‰í•˜ë½ ë¶„ì„
def analyze_rank_changes(today_df, yesterday_df):
    merged = pd.merge(today_df, yesterday_df, on="ì œí’ˆëª…", how="outer", suffixes=("_ì˜¤ëŠ˜", "_ì–´ì œ"))
    merged["ë³€í™”"] = merged["ìˆœìœ„_ì–´ì œ"] - merged["ìˆœìœ„_ì˜¤ëŠ˜"]

    rising = merged.dropna(subset=["ìˆœìœ„_ì˜¤ëŠ˜", "ìˆœìœ„_ì–´ì œ"]).sort_values("ë³€í™”", ascending=False).head(5)
    new_entries = merged[merged["ìˆœìœ„_ì–´ì œ"].isna()].sort_values("ìˆœìœ„_ì˜¤ëŠ˜").head(5)
    falling = merged.dropna(subset=["ìˆœìœ„_ì˜¤ëŠ˜", "ìˆœìœ„_ì–´ì œ"]).sort_values("ë³€í™”", ascending=True).head(5)

    return rising, new_entries, falling

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    today = datetime.now().strftime("%Y-%m-%d")
    os.makedirs("rankings", exist_ok=True)
    csv_name = f"oliveyoung_{today}.csv"
    local_path = os.path.join("rankings", csv_name)

    df_today = asyncio.run(scrape_oliveyoung())
    df_today.to_csv(local_path, index=False, encoding="utf-8-sig")
    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {local_path}")

    # ì–´ì œ ë°ì´í„° ë¶„ì„
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    yesterday_path = os.path.join("rankings", f"oliveyoung_{yesterday}.csv")

    rising = new_entries = falling = pd.DataFrame()
    if os.path.exists(yesterday_path):
        df_yesterday = pd.read_csv(yesterday_path)
        rising, new_entries, falling = analyze_rank_changes(df_today, df_yesterday)

    # Dropbox ì—…ë¡œë“œ
    upload_to_dropbox(local_path, f"/oliveyoung_rankings/{csv_name}")

    # Slack ë©”ì‹œì§€ ìƒì„±
    msg = f":bar_chart: ì˜¬ë¦¬ë¸Œì˜ ì „ì²´ ë­í‚¹ (êµ­ë‚´) ({today})\n\n"
    msg += "*TOP 10*\n"

    for i, row in df_today.head(10).iterrows():
        rank = i + 1
        label = f"[ì˜¤íŠ¹] " if row["ì˜¤íŠ¹"] == "ì˜¤íŠ¹" else ""
        name_link = f"<{row.URL}|{row.ì œí’ˆëª…}>"
        msg += f"{rank}. {label}{name_link} â€” {row.ê°€ê²©}\n"

    if not rising.empty:
        msg += "\n:arrow_up: *ê¸‰ìƒìŠ¹ TOP 5*\n"
        for _, row in rising.iterrows():
            msg += f"- {row.ì œí’ˆëª…}: {int(row.ìˆœìœ„_ì–´ì œ)}ìœ„ â†’ {int(row.ìˆœìœ„_ì˜¤ëŠ˜)}ìœ„ (â–²{int(row.ë³€í™”)})\n"

    if not new_entries.empty:
        msg += "\n:new: *ì‹ ê·œ ì§„ì…*\n"
        for _, row in new_entries.iterrows():
            msg += f"- {row.ì œí’ˆëª…}: {int(row.ìˆœìœ„_ì˜¤ëŠ˜)}ìœ„ (NEW)\n"

    if not falling.empty:
        msg += "\n:arrow_down: *ê¸‰í•˜ë½ TOP 5*\n"
        for _, row in falling.iterrows():
            msg += f"- {row.ì œí’ˆëª…}: {int(row.ìˆœìœ„_ì–´ì œ)}ìœ„ â†’ {int(row.ìˆœìœ„_ì˜¤ëŠ˜)}ìœ„ (â–¼{abs(int(row.ë³€í™”))})\n"

    send_slack_message(msg)
