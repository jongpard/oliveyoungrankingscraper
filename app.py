# app.py
import asyncio
import re
from datetime import datetime
from zoneinfo import ZoneInfo

import pandas as pd
from playwright.async_api import async_playwright, TimeoutError as PWTimeout

KST = ZoneInfo("Asia/Seoul")

BEST_URL = "https://www.oliveyoung.co.kr/store/main/getBest.do"

# ì‚¬ì´íŠ¸ ê°œí¸/ABí…ŒìŠ¤íŠ¸ ëŒ€ì‘: í›„ë³´ ì…€ë ‰í„°ë¥¼ ë„“ê²Œ ì¡ê³ , ì²« ë§¤ì¹­ì„ ì‚¬ìš©
# (ì‰¼í‘œë¡œ ë¬¶ìœ¼ë©´ "OR"ì²˜ëŸ¼ ë™ì‘)
PRODUCT_LIST_SELECTORS = [
    "ul.tab_cont_list li",           # ê³¼ê±° ì…€ë ‰í„°
    "ul.cate_prd_list li",           # ë˜ ë‹¤ë¥¸ ê³¼ê±° ì…€ë ‰í„°
    "ul.prd_list li",                # ì¼ë°˜ ë¦¬ìŠ¤íŠ¸
    "div.best_prd_area ul li",       # ë² ìŠ¤íŠ¸ ì˜ì—­ ë¦¬ìŠ¤íŠ¸
    "div#Container ul li",           # ìµœí›„ì˜ ë³´ë£¨
]
# ê° ì¹´ë“œ ë‚´ë¶€ì—ì„œ ì‹œë„í•  í•˜ìœ„ ì…€ë ‰í„°(ì—¬ëŸ¬ í›„ë³´)
NAME_CANDIDATES = [
    ".tx_name", ".prd_name", ".name", "a .name", "strong", "a[title]"
]
PRICE_CANDIDATES = [
    ".tx_cur", ".cur_price", ".price .num", ".price", ".won", ".cost"
]
RANK_CANDIDATES = [
    ".tx_num", ".num", ".rank", ".best_num", "em", "i"
]
LINK_CANDIDATES = [
    "a", "a.prd_thumb", "a.prd_info"
]

# ì ˆëŒ€ URLë¡œ ë³€í™˜
def to_abs(url: str) -> str:
    if not url:
        return ""
    if url.startswith("http"):
        return url
    return "https://www.oliveyoung.co.kr" + (url if url.startswith("/") else f"/{url}")

def extract_first_text(card, selectors):
    for sel in selectors:
        el = card.query_selector(sel)
        if el:
            txt = (el.get_attribute("title") or "").strip() or (el.inner_text() or "").strip()
            if txt:
                return txt
    return ""

def extract_first_href(card, selectors):
    for sel in selectors:
        el = card.query_selector(sel)
        if el:
            href = el.get_attribute("href") or ""
            if href:
                return to_abs(href)
    return ""

def clean_price(text: str) -> float | None:
    if not text:
        return None
    # ìˆ«ìë§Œ ì¡ì•„ë‚´ê¸°
    m = re.findall(r"\d+", text.replace(",", ""))
    if not m:
        return None
    try:
        return float("".join(m))
    except:
        return None

def clean_rank(text: str) -> float | None:
    if not text:
        return None
    m = re.search(r"\d+", text)
    if not m:
        return None
    try:
        return float(m.group())
    except:
        return None

async def wait_for_any_selector(page, selectors, timeout_ms=30000):
    """
    ì—¬ëŸ¬ í›„ë³´ ì…€ë ‰í„° ì¤‘ í•˜ë‚˜ë¼ë„ ë“±ì¥í•  ë•Œê¹Œì§€ ëŒ€ê¸°.
    """
    combined = ", ".join(selectors)
    await page.locator(combined).first.wait_for(state="visible", timeout=timeout_ms)

async def smart_scroll(page, step_px=1200, max_rounds=15, pause_ms=300):
    """
    ë¬´í•œ ìŠ¤í¬ë¡¤/ì§€ì—° ë¡œë”© ëŒ€ë¹„: ì•„ë˜ë¡œ ì—¬ëŸ¬ ë²ˆ ìŠ¤í¬ë¡¤
    """
    last_height = await page.evaluate("() => document.body.scrollHeight")
    rounds = 0
    while rounds < max_rounds:
        rounds += 1
        await page.mouse.wheel(0, step_px)
        await page.wait_for_timeout(pause_ms)
        new_height = await page.evaluate("() => document.body.scrollHeight")
        if new_height <= last_height:
            break
        last_height = new_height

async def scrape_oliveyoung(max_retries=3) -> pd.DataFrame:
    now_kst = datetime.now(KST)
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=[
            "--disable-blink-features=AutomationControlled",
            "--disable-dev-shm-usage",
            "--no-sandbox",
        ])
        context = await browser.new_context(
            locale="ko-KR",
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
            ),
            viewport={"width": 1440, "height": 900},
        )
        # ê°„ë‹¨ ìŠ¤í…”ìŠ¤: webdriver ê°ì¶”ê¸°
        await context.add_init_script(
            """() => { Object.defineProperty(navigator, 'webdriver', { get: () => undefined }); }"""
        )
        page = await context.new_page()

        attempt = 0
        last_err = None
        while attempt < max_retries:
            attempt += 1
            try:
                print(f"ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘ (ì‹œë„ {attempt}/{max_retries})")
                await page.goto(BEST_URL, wait_until="domcontentloaded", timeout=40000)
                # ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™”
                await page.wait_for_load_state("networkidle", timeout=20000)

                # ì–´ëŠ ë¦¬ìŠ¤íŠ¸ë“  ë³´ì¼ ë•Œê¹Œì§€ ëŒ€ê¸°
                await wait_for_any_selector(page, [s.replace(" li", "") for s in PRODUCT_LIST_SELECTORS], timeout_ms=35000)

                # ìŠ¤í¬ë¡¤ë¡œ ì§€ì—° ë¡œë”© ì²˜ë¦¬
                await smart_scroll(page)

                # ì‹¤ì œ ì¹´ë“œ ìˆ˜ì§‘
                cards = None
                for sel in PRODUCT_LIST_SELECTORS:
                    loc = page.locator(sel)
                    count = await loc.count()
                    if count > 0:
                        cards = [loc.nth(i) for i in range(count)]
                        break

                if not cards:
                    raise RuntimeError("ìƒí’ˆ ì¹´ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì…€ë ‰í„°ê°€ ë³€ê²½ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")

                results = []
                for card in cards:
                    handle = await card.element_handle()
                    if not handle:
                        continue

                    # DOMì—ì„œ ì•ˆì „ ì¶”ì¶œ (ë™ê¸° ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ)
                    name = await handle.evaluate(
                        "(el, sels) => {"
                        "  for (const s of sels){const t=el.querySelector(s);"
                        "    if(t){const v=(t.getAttribute('title')||t.textContent||'').trim();"
                        "      if(v) return v;}} return ''; }",
                        NAME_CANDIDATES
                    )
                    price_text = await handle.evaluate(
                        "(el, sels) => {"
                        "  for (const s of sels){const t=el.querySelector(s);"
                        "    if(t){return (t.textContent||'').trim();}} return ''; }",
                        PRICE_CANDIDATES
                    )
                    rank_text = await handle.evaluate(
                        "(el, sels) => {"
                        "  for (const s of sels){const t=el.querySelector(s);"
                        "    if(t){return (t.textContent||'').trim();}} return ''; }",
                        RANK_CANDIDATES
                    )
                    link = await handle.evaluate(
                        "(el, sels) => {"
                        "  const toAbs = (u)=>{ if(!u) return ''; "
                        "    if(/^https?:\\/\\//i.test(u)) return u;"
                        "    return 'https://www.oliveyoung.co.kr' + (u.startsWith('/')? u : '/' + u); };"
                        "  for (const s of sels){const a=el.querySelector(s);"
                        "    if(a){const href=a.getAttribute('href'); if(href) return toAbs(href);}} return ''; }",
                        LINK_CANDIDATES
                    )

                    price = clean_price(price_text)
                    rank = clean_rank(rank_text)

                    # ë¹„ì–´ìˆëŠ” ì¹´ë“œ(ê´‘ê³ /ë¹ˆ li) ìŠ¤í‚µ
                    if not name and not link:
                        continue

                    results.append({
                        "ìˆ˜ì§‘ì¼ì": now_kst.strftime("%Y-%m-%d"),
                        "ì œí’ˆëª…": name,
                        "ê°€ê²©": price,
                        "ë§í¬": link,
                        "ìˆœìœ„": rank,
                    })

                df = pd.DataFrame(results)

                # ì˜¤íŠ¹: ìˆœìœ„ê°€ NaNì¸ ê²½ìš° True
                df["ì˜¤íŠ¹"] = df["ìˆœìœ„"].isna()

                # ìµœì†Œ ê²€ì¦: ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬ (ì‚¬ì´íŠ¸ ì¼ì‹œ ì˜¤ë¥˜ ë°©ì§€)
                if len(df) < 5:
                    raise RuntimeError(f"ìˆ˜ì§‘ ê²°ê³¼ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ì ìŠµë‹ˆë‹¤. ({len(df)}ê±´)")

                await context.close()
                await browser.close()
                return df

            except (PWTimeout, RuntimeError) as e:
                last_err = e
                print(f"âš ï¸ ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
                # ìƒˆë¡œê³ ì¹¨ í›„ ì¬ì‹œë„
                try:
                    await page.reload(timeout=25000)
                    await page.wait_for_load_state("domcontentloaded", timeout=20000)
                except Exception:
                    pass

        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
        if last_err:
            raise last_err
        raise RuntimeError("ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ ë¡œ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

def save_csv_kst(df: pd.DataFrame) -> str:
    now_kst = datetime.now(KST)
    fname = now_kst.strftime("oliveyoung_rank_%Y%m%d.csv")
    df.to_csv(fname, index=False, encoding="utf-8-sig")
    return fname

if __name__ == "__main__":
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘ (Playwright ìš°íšŒ)")
    df_today = asyncio.run(scrape_oliveyoung())
    csv_path = save_csv_kst(df_today)
    print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(df_today)}ê±´, CSV ì €ì¥: {csv_path}")

    # ë””ë²„ê¹… ì¶œë ¥ (ì•ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°)
    with pd.option_context("display.max_colwidth", 120):
        print(df_today.head(10))
