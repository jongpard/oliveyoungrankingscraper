import os
import re
import json
import base64
import datetime
import pandas as pd
from playwright.sync_api import sync_playwright
from google.oauth2 import service_account
from googleapiclient.discovery import build
import requests

# í™˜ê²½ë³€ìˆ˜
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")
GDRIVE_SA_JSON_B64 = os.getenv("GDRIVE_SA_JSON_B64")
GDRIVE_FOLDER_ID = os.getenv("GDRIVE_FOLDER_ID")

TODAY = datetime.date.today().strftime("%Y-%m-%d")
RANKINGS_DIR = "rankings"
os.makedirs(RANKINGS_DIR, exist_ok=True)

# Google Drive ì—…ë¡œë“œ í•¨ìˆ˜
def upload_to_gdrive(file_path, file_name):
    creds_json = base64.b64decode(GDRIVE_SA_JSON_B64).decode("utf-8")
    creds_dict = json.loads(creds_json)
    creds = service_account.Credentials.from_service_account_info(
        creds_dict, scopes=["https://www.googleapis.com/auth/drive.file"]
    )
    service = build("drive", "v3", credentials=creds)

    file_metadata = {
        "name": file_name,
        "parents": [GDRIVE_FOLDER_ID]
    }
    media = MediaFileUpload(file_path, mimetype="text/csv")
    uploaded = service.files().create(
        body=file_metadata, media_body=media, fields="id"
    ).execute()
    print(f"âœ… Google Drive ì—…ë¡œë“œ ì™„ë£Œ: {uploaded.get('id')}")

# ì œí’ˆëª… ì •ë¦¬ (ì•ì˜ ë¶ˆí•„ìš” íƒœê·¸ ì œê±°)
def clean_product_name(name):
    return re.sub(r"^\[.*?\]\s*", "", name).strip()

# ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ í¬ë¡¤ë§
def scrape_rankings():
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘")
    data = []
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.goto("https://www.oliveyoung.co.kr/store/main/getBestList.do", timeout=60000)
        page.wait_for_selector(".prd_info")
        products = page.query_selector_all(".prd_info")

        rank_counter = 1
        for prod in products:
            rank_text = prod.query_selector(".num").inner_text().strip()
            # 'ì˜¤íŠ¹' ë¬´ì‹œí•˜ê³  ìˆœì„œëŒ€ë¡œ ë­í‚¹ ë²ˆí˜¸ ë¶€ì—¬
            if "ì˜¤íŠ¹" in rank_text:
                rank_text = str(rank_counter)
            name = prod.query_selector(".tx_name").inner_text().strip()
            brand = prod.query_selector(".tx_brand").inner_text().strip()
            price = prod.query_selector(".tx_cur").inner_text().strip()
            data.append({
                "ìˆœìœ„": int(rank_text),
                "ë¸Œëœë“œ": brand,
                "ì œí’ˆëª…": name,
                "ê°€ê²©": price
            })
            rank_counter += 1
        browser.close()

    df = pd.DataFrame(data)
    file_path = os.path.join(RANKINGS_DIR, f"{TODAY}_oliveyoung.csv")
    df.to_csv(file_path, index=False, encoding="utf-8-sig")
    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {file_path}")
    return df, file_path

# ë­í‚¹ ë³€ë™ ë¶„ì„
def analyze_trends(df_today):
    try:
        yesterday = (datetime.date.today() - datetime.timedelta(days=1)).strftime("%Y-%m-%d")
        yesterday_file = os.path.join(RANKINGS_DIR, f"{yesterday}_oliveyoung.csv")
        if not os.path.exists(yesterday_file):
            print("âš  ì–´ì œ ë°ì´í„° ì—†ìŒ, íŠ¸ë Œë“œ ë¶„ì„ ë¶ˆê°€")
            return ""
        df_yesterday = pd.read_csv(yesterday_file)

        merged = pd.merge(
            df_today, df_yesterday, on="ì œí’ˆëª…", suffixes=("_today", "_yesterday"), how="left"
        )
        merged["ë³€ë™"] = merged["ìˆœìœ„_yesterday"] - merged["ìˆœìœ„_today"]
        merged = merged.sort_values("ë³€ë™", ascending=False).head(5)

        analysis = "ğŸ”¥ ê¸‰ìƒìŠ¹ ë¸Œëœë“œ\n"
        for _, row in merged.iterrows():
            change_str = f"(+{row['ë³€ë™']})" if row["ë³€ë™"] > 0 else f"({row['ë³€ë™']})"
            brand = row["ë¸Œëœë“œ_today"]
            prod_name = clean_product_name(row["ì œí’ˆëª…"])
            if pd.isna(row["ìˆœìœ„_yesterday"]):
                rank_change = f"ì²« ë“±ì¥ {row['ìˆœìœ„_today']}ìœ„"
            else:
                rank_change = f"{int(row['ìˆœìœ„_yesterday'])}ìœ„ â†’ {int(row['ìˆœìœ„_today'])}ìœ„ {change_str}"
            analysis += f"- {brand}: {rank_change}\n â–¶ {brand} {prod_name}\n"
        return analysis
    except Exception as e:
        print(f"íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return ""

# Slack ì „ì†¡
def send_to_slack(message):
    payload = {"text": message}
    res = requests.post(SLACK_WEBHOOK_URL, json=payload)
    if res.status_code == 200:
        print("âœ… Slack ì „ì†¡ ì™„ë£Œ")
    else:
        print(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {res.status_code}")

if __name__ == "__main__":
    df_today, file_path = scrape_rankings()
    upload_to_gdrive(file_path, os.path.basename(file_path))

    top10_msg = "ğŸ† ì˜¤ëŠ˜ì˜ ë­í‚¹ TOP 10\n"
    for _, row in df_today.head(10).iterrows():
        top10_msg += f"{row['ìˆœìœ„']}ìœ„: {row['ë¸Œëœë“œ']} {row['ì œí’ˆëª…']} - {row['ê°€ê²©']}\n"

    trend_msg = analyze_trends(df_today)

    final_msg = f"{top10_msg}\n\n{trend_msg}"
    send_to_slack(final_msg)
