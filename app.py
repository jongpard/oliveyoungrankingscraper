# app.py
import asyncio
import os
import re
from datetime import datetime
from zoneinfo import ZoneInfo

import pandas as pd
from playwright.async_api import async_playwright, TimeoutError as PWTimeout

KST = ZoneInfo("Asia/Seoul")
BEST_URL = "https://www.oliveyoung.co.kr/store/main/getBest.do"

PRODUCT_LIST_SELECTORS = [
    "ul.tab_cont_list li",
    "ul.cate_prd_list li",
    "ul.prd_list li",
    "div.best_prd_area ul li",
    "div#Container ul li",
]

NAME_CANDIDATES = [".tx_name", ".prd_name", ".name", "a .name", "strong", "a[title]"]
PRICE_CANDIDATES = [".tx_cur", ".cur_price", ".price .num", ".price", ".won", ".cost"]
RANK_CANDIDATES = [".tx_num", ".num", ".rank", ".best_num", "em", "i"]
LINK_CANDIDATES = ["a", "a.prd_thumb", "a.prd_info"]

def to_abs(url: str) -> str:
    if not url:
        return ""
    if url.startswith("http"):
        return url
    return "https://www.oliveyoung.co.kr" + (url if url.startswith("/") else f"/{url}")

def clean_price(text: str):
    if not text: return None
    m = re.findall(r"\d+", text.replace(",", ""))
    if not m: return None
    try: return float("".join(m))
    except: return None

def clean_rank(text: str):
    if not text: return None
    m = re.search(r"\d+", text)
    if not m: return None
    try: return float(m.group())
    except: return None

async def close_popups(page):
    # ì¿ í‚¤/ì•½ê´€/ê´‘ê³  íŒì—… ëŒ€ì¶© ë‹«ê¸°
    candidates = [
        "button:has-text('ë™ì˜')", "button:has-text('í™•ì¸')", "button:has-text('ë‹«ê¸°')",
        "a:has-text('ë™ì˜')", "a:has-text('í™•ì¸')", "a:has-text('ë‹«ê¸°')",
        "#chkToday", ".btnClose", ".btn-close", ".oy-cookie-accept",
        "div.layerPop button", "div.popup button"
    ]
    for sel in candidates:
        try:
            btn = page.locator(sel)
            if await btn.count() > 0:
                await btn.first.click(timeout=1000)
                await page.wait_for_timeout(300)
        except Exception:
            pass

async def wait_product_list(page, timeout_ms=35000):
    # 1) attached(ë¶™ê¸°ë§Œ í•´ë„) â†’ 2) visible(ë³´ì¼ ë•Œê¹Œì§€) â†’ 3) ê°œìˆ˜ ê²€ì¦
    roots = [s.replace(" li", "") for s in PRODUCT_LIST_SELECTORS]
    combined_root = ", ".join(roots)
    try:
        await page.locator(combined_root).first.wait_for(state="attached", timeout=timeout_ms//2)
    except PWTimeout:
        # ìµœí›„: ê°œìˆ˜ í•¨ìˆ˜ë¡œ ì¬ì‹œë„
        pass

    try:
        await page.locator(combined_root).first.wait_for(state="visible", timeout=timeout_ms//2)
    except PWTimeout:
        # ì¼ë¶€ í™˜ê²½ì—ì„œ display ì²˜ë¦¬ ì§€ì—° â†’ ê°œìˆ˜ ê²€ì‚¬ë¡œ ë„˜ì–´ê°
        pass

    # liê°€ 5ê°œ ì´ìƒ ë¶™ìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
    selectors_js_array = "[" + ",".join([f"'{s}'" for s in PRODUCT_LIST_SELECTORS]) + "]"
    await page.wait_for_function(
        """(sels) => {
            for (const s of sels){
              const els = document.querySelectorAll(s);
              if (els && els.length >= 5) return true;
            }
            return false;
        }""",
        arg=PRODUCT_LIST_SELECTORS,
        timeout=timeout_ms
    )

async def smart_scroll(page, step_px=1200, max_rounds=15, pause_ms=300):
    last_h = await page.evaluate("() => document.body.scrollHeight")
    for _ in range(max_rounds):
        await page.mouse.wheel(0, step_px)
        await page.wait_for_timeout(pause_ms)
        new_h = await page.evaluate("() => document.body.scrollHeight")
        if new_h <= last_h:
            break
        last_h = new_h

async def dump_debug(page, prefix="debug"):
    os.makedirs("artifacts", exist_ok=True)
    try:
        await page.screenshot(path=f"artifacts/{prefix}.png", full_page=True)
    except Exception:
        pass
    try:
        html = await page.content()
        with open(f"artifacts/{prefix}.html", "w", encoding="utf-8") as f:
            f.write(html)
    except Exception:
        pass
    # ì½˜ì†” ëŒ€ë¹„ ë³¸ë¬¸ ì¼ë¶€ ë¡œê·¸
    try:
        text_preview = await page.eval_on_selector("body", "el => el.innerText.slice(0, 2000)")
        print("----- BODY PREVIEW -----")
        print(text_preview)
        print("----- /BODY PREVIEW -----")
    except Exception:
        pass

async def scrape_oliveyoung(max_retries=3) -> pd.DataFrame:
    now_kst = datetime.now(KST)
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=[
            "--disable-blink-features=AutomationControlled",
            "--disable-dev-shm-usage",
            "--no-sandbox",
        ])
        context = await browser.new_context(
            locale="ko-KR",
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
            ),
            viewport={"width": 1440, "height": 900},
            java_script_enabled=True,
            extra_http_headers={
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            },
        )
        await context.add_init_script("""
            () => {
              Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
              Object.defineProperty(navigator, 'languages', { get: () => ['ko-KR','ko','en-US','en'] });
              Object.defineProperty(navigator, 'plugins', { get: () => [1,2,3] });
            }
        """)
        page = await context.new_page()

        attempt = 0
        last_err = None
        while attempt < max_retries:
            attempt += 1
            try:
                print(f"ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘ (ì‹œë„ {attempt}/{max_retries})")
                await page.goto(BEST_URL, wait_until="load", timeout=50000)
                await page.wait_for_load_state("domcontentloaded", timeout=30000)
                await close_popups(page)

                # ë„¤íŠ¸ì›Œí¬ê°€ ì ì í•´ì§„ ë’¤ ì ê¹ ëŒ€ê¸°(ì§€ì—° ë Œë”ë§ ëŒ€ë¹„)
                try:
                    await page.wait_for_load_state("networkidle", timeout=20000)
                except Exception:
                    pass
                await page.wait_for_timeout(500)

                # ìŠ¤í¬ë¡¤ ë¡œë”©
                await smart_scroll(page)
                await close_popups(page)

                # ì œí’ˆ ë¦¬ìŠ¤íŠ¸ ëŒ€ê¸°(ë³´ì´ë“ , ë¶™ì–´ìˆë“ , ê°œìˆ˜ë“  ë¬´ì—‡ì´ë“ )
                await wait_product_list(page, timeout_ms=40000)

                # ê°€ì¥ ë§ì€ lië¥¼ ê°€ì§„ ì…€ë ‰í„° ì„ íƒ
                best_sel = None
                best_cnt = 0
                for sel in PRODUCT_LIST_SELECTORS:
                    cnt = await page.locator(sel).count()
                    if cnt > best_cnt:
                        best_cnt = cnt
                        best_sel = sel
                if not best_sel or best_cnt == 0:
                    raise RuntimeError("ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

                loc = page.locator(best_sel)
                cards = [loc.nth(i) for i in range(await loc.count())]

                results = []
                for card in cards:
                    handle = await card.element_handle()
                    if not handle:
                        continue

                    name = await handle.evaluate(
                        "(el, sels) => {"
                        "  for (const s of sels){const t=el.querySelector(s);"
                        "    if(t){const v=(t.getAttribute('title')||t.textContent||'').trim();"
                        "      if(v) return v;}} return ''; }",
                        NAME_CANDIDATES
                    )
                    price_text = await handle.evaluate(
                        "(el, sels) => {"
                        "  for (const s of sels){const t=el.querySelector(s);"
                        "    if(t){return (t.textContent||'').trim();}} return ''; }",
                        PRICE_CANDIDATES
                    )
                    rank_text = await handle.evaluate(
                        "(el, sels) => {"
                        "  for (const s of sels){const t=el.querySelector(s);"
                        "    if(t){return (t.textContent||'').trim();}} return ''; }",
                        RANK_CANDIDATES
                    )
                    link = await handle.evaluate(
                        "(el, sels) => {"
                        "  const toAbs = (u)=>{ if(!u) return ''; "
                        "    if(/^https?:\\/\\//i.test(u)) return u;"
                        "    return 'https://www.oliveyoung.co.kr' + (u.startsWith('/')? u : '/' + u); };"
                        "  for (const s of sels){const a=el.querySelector(s);"
                        "    if(a){const href=a.getAttribute('href'); if(href) return toAbs(href);}} return ''; }",
                        LINK_CANDIDATES
                    )

                    # ê´‘ê³ ì„± ë¹ˆ li ìŠ¤í‚µ
                    if not name and not link:
                        continue

                    results.append({
                        "ìˆ˜ì§‘ì¼ì": now_kst.strftime("%Y-%m-%d"),
                        "ì œí’ˆëª…": name,
                        "ê°€ê²©": clean_price(price_text),
                        "ë§í¬": link,
                        "ìˆœìœ„": clean_rank(rank_text),
                    })

                df = pd.DataFrame(results)
                df["ì˜¤íŠ¹"] = df["ìˆœìœ„"].isna()

                if len(df) < 5:
                    raise RuntimeError(f"ìˆ˜ì§‘ ê²°ê³¼ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ì ìŠµë‹ˆë‹¤. ({len(df)}ê±´)")

                await context.close()
                await browser.close()
                return df

            except (PWTimeout, RuntimeError) as e:
                last_err = e
                print(f"âš ï¸ ì‹œë„ {attempt} ì‹¤íŒ¨: {e}")
                await dump_debug(page, prefix=f"fail_attempt_{attempt}")
                # ìƒˆë¡œê³ ì¹¨ í›„ ì¬ì‹œë„
                try:
                    await page.reload(timeout=25000)
                    await page.wait_for_load_state("domcontentloaded", timeout=20000)
                except Exception:
                    pass

        if last_err:
            raise last_err
        raise RuntimeError("ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ ë¡œ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

def save_csv_kst(df: pd.DataFrame) -> str:
    now_kst = datetime.now(KST)
    fname = now_kst.strftime("oliveyoung_rank_%Y%m%d.csv")
    df.to_csv(fname, index=False, encoding="utf-8-sig")
    return fname

if __name__ == "__main__":
    print("ğŸ” ì˜¬ë¦¬ë¸Œì˜ ë­í‚¹ ìˆ˜ì§‘ ì‹œì‘ (Playwright ìš°íšŒ)")
    df_today = asyncio.run(scrape_oliveyoung())
    csv_path = save_csv_kst(df_today)
    print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(df_today)}ê±´, CSV ì €ì¥: {csv_path}")

    with pd.option_context("display.max_colwidth", 120):
        print(df_today.head(10))
