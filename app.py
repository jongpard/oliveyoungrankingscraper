import os
import re
import json
import base64
import requests
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.service_account import Credentials
from googleapiclient.errors import HttpError  # HttpErrorë¥¼ ëª…ì‹œì ìœ¼ë¡œ import

# í™˜ê²½ë³€ìˆ˜
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")
GDRIVE_SA_JSON_B64 = os.getenv("GDRIVE_SA_JSON_B64")
GDRIVE_FOLDER_ID = os.getenv("GDRIVE_FOLDER_ID")

# ëž­í‚¹ ì €ìž¥ í´ë”
CSV_DIR = "rankings"
os.makedirs(CSV_DIR, exist_ok=True)

# ===============================
# í¬ë¡¤ë§ í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
# ===============================
def scrape_oliveyoung():
    url = "https://www.oliveyoung.co.kr/store/main/getBestList.do?t_page=%ED%99%88&t_click=GNB&t_gnb_type=%EB%9E%AD%ED%82%B9&t_swiping_type=N"
    # User-AgentëŠ” ì¡°ê¸ˆ ë” ì¼ë°˜ì ì¸ ë¸Œë¼ìš°ì € í˜•íƒœë¡œ ì§€ì •í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ìž…ë‹ˆë‹¤.
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    r = requests.get(url, headers=headers)
    r.raise_for_status() # ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
    soup = BeautifulSoup(r.text, "html.parser")

    products = soup.select("ul.cate_prd_list li")
    data = []
    rank_counter = 1

    for p in products:
        rank_tag = p.select_one(".num")
        current_rank = rank_counter # ê¸°ë³¸ê°’ì€ ì´ì „ ìˆœìœ„+1
        if rank_tag and rank_tag.get_text(strip=True).isdigit():
             current_rank = int(rank_tag.get_text(strip=True))
        
        rank_counter = current_rank # ë‹¤ìŒ ìˆœë²ˆì„ ìœ„í•´ ì‹¤ì œ ìˆœìœ„ë¡œ ì—…ë°ì´íŠ¸
        
        brand = p.select_one(".prd_brand").get_text(strip=True) if p.select_one(".prd_brand") else ""
        name = p.select_one(".prd_name").get_text(strip=True) if p.select_one(".prd_name") else ""
        price_raw = p.select_one(".price-value")
        price = price_raw.get_text(strip=True) if price_raw else "ê°€ê²© ì •ë³´ ì—†ìŒ"

        data.append({
            "rank": current_rank,
            "brand": brand,
            "name": name,
            "price": price
        })
        rank_counter += 1

    df = pd.DataFrame(data)
    return df

# ===============================
# ë°ì´í„° ë¶„ì„ í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
# ===============================
def analyze_trends(today_df, prev_df):
    if prev_df.empty:
        return [], []
    
    today_ranks = {row["name"]: row["rank"] for _, row in today_df.iterrows()}
    prev_ranks = {row["name"]: row["rank"] for _, row in prev_df.iterrows()}

    rising = []
    falling = []

    for name, prev_rank in prev_ranks.items():
        if name in today_ranks:
            diff = prev_rank - today_ranks[name]
            if diff >= 10:
                rising.append((name, prev_rank, today_ranks[name], diff))
            elif diff <= -10:
                falling.append((name, prev_rank, today_ranks[name], diff))
        else:
            if prev_rank <= 50:
                falling.append((name, prev_rank, "ëž­í¬ì•„ì›ƒ", None))

    return rising, falling

# ===============================
# êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ (âœ¨ ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ìž…ë‹ˆë‹¤ âœ¨)
# ===============================
def upload_to_drive(local_path, folder_id):
    """
    try-except êµ¬ë¬¸ì„ ì¶”ê°€í•˜ì—¬ ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì›ì¸ì„ ëª…í™•ížˆ íŒŒì•…í•˜ë„ë¡ ìˆ˜ì •
    """
    try:
        print("ðŸš€ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
        creds_json = base64.b64decode(GDRIVE_SA_JSON_B64).decode()
        creds_dict = json.loads(creds_json)
        creds = Credentials.from_service_account_info(
            creds_dict, scopes=['https://www.googleapis.com/auth/drive']
        )
        service = build('drive', 'v3', credentials=creds)

        file_metadata = {
            "name": os.path.basename(local_path),
            "parents": [folder_id]
        }
        media = MediaFileUpload(local_path, mimetype="text/csv")
        
        service.files().create(
            body=file_metadata,
            media_body=media,
            fields="id",
            supportsAllDrives=True
        ).execute()
        
        print(f"âœ… Google Drive ì—…ë¡œë“œ ì™„ë£Œ: {os.path.basename(local_path)}")

    except HttpError as error:
        # êµ¬ê¸€ APIì—ì„œ ë°œìƒí•œ ì—ëŸ¬ë¥¼ ìž¡ì•„ ëª…í™•í•œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        error_details = error.content.decode('utf-8')
        print(f"âŒ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹¤íŒ¨! ì›ì¸: {error_details}")
        if 'storageQuotaExceeded' in error_details:
            raise Exception("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê¶Œí•œ ì˜¤ë¥˜: ì„œë¹„ìŠ¤ ê³„ì •ì€ ì €ìž¥ ê³µê°„ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì €ìž¥í•  êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë”ì˜ 'ê³µìœ ' ì„¤ì •ì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì¶”ê°€í•˜ê³  'íŽ¸ì§‘ìž' ê¶Œí•œì„ ë¶€ì—¬í–ˆëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif 'File not found' in error_details:
             raise Exception(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë” ì°¾ê¸° ì˜¤ë¥˜: GitHub Secretsì— ë“±ë¡ëœ í´ë” ID({folder_id})ê°€ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            raise Exception(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œ API ì—ëŸ¬: {error_details}")
    except Exception as e:
        # ê·¸ ì™¸ ì˜ˆê¸°ì¹˜ ëª»í•œ ì—ëŸ¬ ì²˜ë¦¬
        print(f"âŒ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬ ë°œìƒ: {e}")
        raise e

# ===============================
# Slack ì „ì†¡ (ìˆ˜ì • ì—†ìŒ)
# ===============================
def send_to_slack(message):
    if not SLACK_WEBHOOK_URL:
        print("ìŠ¬ëž™ ì›¹í›… URLì´ ì—†ìŠµë‹ˆë‹¤. ì•Œë¦¼ì„ ìƒëžµí•©ë‹ˆë‹¤.")
        return
    payload = {"text": message}
    requests.post(SLACK_WEBHOOK_URL, json=payload)

# ===============================
# ì‹¤í–‰ (âœ¨ ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” âœ¨)
# ===============================
if __name__ == "__main__":
    # ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ try-exceptë¡œ ê°ì‹¸ì„œ ì–´ëŠ ë‹¨ê³„ì—ì„œë“  ì—ëŸ¬ê°€ ë‚˜ë©´ ìŠ¬ëž™ìœ¼ë¡œ ì•Œë¦¼
    try:
        print("ðŸ” ì˜¬ë¦¬ë¸Œì˜ ëž­í‚¹ ìˆ˜ì§‘ ì‹œìž‘")
        today_df = scrape_oliveyoung()
        today_str = datetime.now().strftime("%Y-%m-%d")
        csv_path = os.path.join(CSV_DIR, f"oliveyoung_{today_str}.csv")
        today_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ë¡œì»¬ì— CSV ì €ìž¥ ì™„ë£Œ: {csv_path}")

        # ì–´ì œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ë¶„ì„ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
        prev_df = pd.DataFrame()
        # ... (ë¶„ì„ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ë‘ì—ˆìŠµë‹ˆë‹¤) ...

        # ìŠ¬ëž™ ë©”ì‹œì§€ ë°œì†¡
        msg = f":bar_chart: ì˜¬ë¦¬ë¸Œì˜ ì „ì²´ ëž­í‚¹ (êµ­ë‚´) ({today_str})\n"
        for _, row in today_df.head(10).iterrows():
            msg += f"{row['rank']}. {row['brand']} - {row['name']} ({row['price']})\n"
        send_to_slack(msg)
        print("âœ… ìŠ¬ëž™ìœ¼ë¡œ ëž­í‚¹ ì •ë³´ ì „ì†¡ ì™„ë£Œ.")

        # êµ¬ê¸€ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
        upload_to_drive(csv_path, GDRIVE_FOLDER_ID)

        # ìµœì¢… ì„±ê³µ ë©”ì‹œì§€
        send_to_slack(f"ðŸŽ‰ [{today_str}] ëª¨ë“  ìž‘ì—…(ìˆ˜ì§‘, ì €ìž¥, ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ)ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë‚´ìš©ì„ ë‹´ì•„ ìŠ¬ëž™ìœ¼ë¡œ ì „ì†¡
        error_message = f"ðŸš¨ [ì‹¤íŒ¨] ìžë™í™” ìž‘ì—… ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n- ë°œìƒ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n- ì—ëŸ¬ ì›ì¸: `{e}`"
        print(error_message)
        send_to_slack(error_message)
